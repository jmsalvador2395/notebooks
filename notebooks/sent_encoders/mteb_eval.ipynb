{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[35mNOTE\u001b[0m] changed directory to '/data/john/projects/mltoolkit'\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "import os\n",
    "import umap\n",
    "import evaluate\n",
    "import accelerate\n",
    "from mteb import MTEB\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from IPython.core.debugger import set_trace\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk import sent_tokenize\n",
    "from IPython.core.debugger import Pdb\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pprint import pprint\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from itertools import chain\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "from nbtools.sent_encoders.hf_models import from_hf\n",
    "from nbtools.utils import (\n",
    "    files,\n",
    "    tensor_utils,\n",
    "    display,\n",
    ")\n",
    "os.chdir('/data/john/projects/mltoolkit/')\n",
    "cache_dir='./data/cache'\n",
    "display.note(f'changed directory to \\'{os.getcwd()}\\'')\n",
    "\n",
    "datasets.disable_caching()\n",
    "\n",
    "# Set this to whatever you want\n",
    "seed = 10\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mixedbread-ai/mxbai-embed-large-v1'\n",
    "encoder = from_hf(\n",
    "    model_name, \n",
    "    emb_dim=1024, \n",
    "    max_seq_len=512,\n",
    "    cache_dir='./',\n",
    ")\n",
    "\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_LIST_CLASSIFICATION = [\n",
    "    \"AmazonCounterfactualClassification\",\n",
    "    \"AmazonPolarityClassification\",\n",
    "    \"AmazonReviewsClassification\",\n",
    "    \"Banking77Classification\",\n",
    "    \"EmotionClassification\",\n",
    "    \"ImdbClassification\",\n",
    "    \"MassiveIntentClassification\",\n",
    "    \"MassiveScenarioClassification\",\n",
    "    \"MTOPDomainClassification\",\n",
    "    \"MTOPIntentClassification\",\n",
    "    \"ToxicConversationsClassification\",\n",
    "    \"TweetSentimentExtractionClassification\",\n",
    "]\n",
    "\n",
    "TASK_LIST_CLUSTERING = [\n",
    "    \"ArxivClusteringP2P\",\n",
    "    \"ArxivClusteringS2S\",\n",
    "    \"BiorxivClusteringP2P\",\n",
    "    \"BiorxivClusteringS2S\",\n",
    "    \"MedrxivClusteringP2P\",\n",
    "    \"MedrxivClusteringS2S\",\n",
    "    \"RedditClustering\",\n",
    "    \"RedditClusteringP2P\",\n",
    "    \"StackExchangeClustering\",\n",
    "    \"StackExchangeClusteringP2P\",\n",
    "    \"TwentyNewsgroupsClustering\",\n",
    "]\n",
    "\n",
    "TASK_LIST_PAIR_CLASSIFICATION = [\n",
    "    \"SprintDuplicateQuestions\",\n",
    "    \"TwitterSemEval2015\",\n",
    "    \"TwitterURLCorpus\",\n",
    "]\n",
    "\n",
    "TASK_LIST_RERANKING = [\n",
    "    \"AskUbuntuDupQuestions\",\n",
    "    \"MindSmallReranking\",\n",
    "    \"SciDocsRR\",\n",
    "    \"StackOverflowDupQuestions\",\n",
    "]\n",
    "\n",
    "TASK_LIST_RETRIEVAL = [\n",
    "    \"ArguAna\",\n",
    "    \"ClimateFEVER\",\n",
    "    \"CQADupstackAndroidRetrieval\",\n",
    "    \"CQADupstackEnglishRetrieval\",\n",
    "    \"CQADupstackGamingRetrieval\",\n",
    "    \"CQADupstackGisRetrieval\",\n",
    "    \"CQADupstackMathematicaRetrieval\",\n",
    "    \"CQADupstackPhysicsRetrieval\",\n",
    "    \"CQADupstackProgrammersRetrieval\",\n",
    "    \"CQADupstackStatsRetrieval\",\n",
    "    \"CQADupstackTexRetrieval\",\n",
    "    \"CQADupstackUnixRetrieval\",\n",
    "    \"CQADupstackWebmastersRetrieval\",\n",
    "    \"CQADupstackWordpressRetrieval\",\n",
    "    \"DBPedia\",\n",
    "    \"FEVER\",\n",
    "    \"FiQA2018\",\n",
    "    \"HotpotQA\",\n",
    "    \"MSMARCO\",\n",
    "    \"NFCorpus\",\n",
    "    \"NQ\",\n",
    "    \"QuoraRetrieval\",\n",
    "    \"SCIDOCS\",\n",
    "    \"SciFact\",\n",
    "    \"Touche2020\",\n",
    "    \"TRECCOVID\",\n",
    "]\n",
    "\n",
    "TASK_LIST_STS = [\n",
    "    \"BIOSSES\",\n",
    "    \"SICK-R\",\n",
    "    \"STS12\",\n",
    "    \"STS13\",\n",
    "    \"STS14\",\n",
    "    \"STS15\",\n",
    "    \"STS16\",\n",
    "    \"STS17\",\n",
    "    \"STS22\",\n",
    "    \"STSBenchmark\",\n",
    "    \"SummEval\",\n",
    "]\n",
    "\n",
    "TASK_LIST = (\n",
    "    TASK_LIST_CLASSIFICATION\n",
    "    + TASK_LIST_CLUSTERING\n",
    "    + TASK_LIST_PAIR_CLASSIFICATION\n",
    "    + TASK_LIST_RERANKING\n",
    "    + TASK_LIST_RETRIEVAL\n",
    "    + TASK_LIST_STS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in TASK_LIST:\n",
    "    print(f'evaluating {model_name} on {task} ...')\n",
    "    eval_splits = [\"dev\"] if task == \"MSMARCO\" else [\"test\"]\n",
    "    evaluation = MTEB(\n",
    "        tasks=[task], task_langs=[\"en\"]\n",
    "    )  # Remove \"en\" for running all languages\n",
    "    evaluation.run(\n",
    "        encoder, \n",
    "        output_folder=f'{files.project_root()}/results/mteb/{model_name}',\n",
    "        eval_splits=eval_splits,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
