{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "import os\n",
    "#import umap\n",
    "import sys\n",
    "import evaluate\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from IPython.core.debugger import set_trace\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch import nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Transformer, Pooling\n",
    "from nltk import sent_tokenize\n",
    "from IPython.core.debugger import Pdb, set_trace\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import util\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from pprint import pprint\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "from nbtools.utils import files, strings\n",
    "from nbtools.sent_encoders import from_hf\n",
    "\n",
    "datasets.disable_caching()\n",
    "\n",
    "cache_dir = '/data/john/cache'\n",
    "proot = files.project_root()\n",
    "\n",
    "# Set this to whatever you want\n",
    "seed = 10\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets, Standardize Column Names, and Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    allsides: Dataset({\n",
      "        features: ['d1', 'd2', 'ref0', 'ref1', 'ref2', 'ref3', 'name'],\n",
      "        num_rows: 137\n",
      "    })\n",
      "    ppp: Dataset({\n",
      "        features: ['d1', 'd2', 'ref0', 'ref1', 'ref2', 'name'],\n",
      "        num_rows: 135\n",
      "    })\n",
      "    agg: Dataset({\n",
      "        features: ['d1', 'd2', 'ref0', 'ref1', 'ref2', 'ref3', 'name'],\n",
      "        num_rows: 272\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "allsides_dir = '/data/john/datasets/all_sides/test.json'\n",
    "ppp_dir = '/data/john/datasets/privacy_policy/3p_data.csv'\n",
    "\n",
    "raw_ds = DatasetDict({\n",
    "    'allsides': Dataset.from_json(allsides_dir),\n",
    "    'ppp': Dataset.from_csv(ppp_dir),\n",
    "})\n",
    "\n",
    "cols = {\n",
    "    'allsides': ['Left',\n",
    "                 'Right',\n",
    "                 'Ahmed_Intersection',\n",
    "                 'Naman_Intersection',\n",
    "                 'Helen_Intersection',\n",
    "                 'AllSides_Intersection',],\n",
    "    'ppp': ['Company_1',\n",
    "            'Company_2',\n",
    "            'Annotator1',\n",
    "            'Annotator2',\n",
    "            'Annotator3']\n",
    "}\n",
    "\n",
    "col_maps = {\n",
    "    'allsides': {'Left': 'd1',\n",
    "                 'Right': 'd2',\n",
    "                 'Ahmed_Intersection': 'ref0',\n",
    "                 'Naman_Intersection': 'ref1',\n",
    "                 'Helen_Intersection': 'ref2',\n",
    "                 'AllSides_Intersection': 'ref3'},\n",
    "    'ppp': {'Company_1': 'd1',\n",
    "            'Company_2': 'd2',\n",
    "            'Annotator1': 'ref0',\n",
    "            'Annotator2': 'ref1',\n",
    "            'Annotator3': 'ref2'}\n",
    "}\n",
    "\n",
    "# remove extraneous columns\n",
    "ds = DatasetDict({})\n",
    "keep_cols = set(col_maps['allsides'].values())\n",
    "for ds_key, ds_val in raw_ds.items():\n",
    "    ds[ds_key] = ds_val.remove_columns(set(ds_val.features.keys()) - set(cols[ds_key]))\n",
    "\n",
    "\n",
    "# standardize column names\n",
    "for ds_key, ds_val in ds.items():\n",
    "    for old_name, new_name in col_maps[ds_key].items():\n",
    "        ds_val = ds_val.rename_column(old_name, new_name)\n",
    "    ds[ds_key] = ds_val\n",
    "\n",
    "# add ds name as column to both datasets\n",
    "for ds_key, ds_val in ds.items():\n",
    "    ds[ds_key] = ds_val.add_column('name', [ds_key]*len(ds_val))\n",
    "\n",
    "# concatenate datasets\n",
    "ds['agg'] = datasets.concatenate_datasets(ds.values())\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mixedbread-ai/mxbai-embed-large-v1'\n",
    "model = from_hf(model_name, \n",
    "                emb_dim=1024, \n",
    "                max_seq_len=512,\n",
    "                cache_dir=f'{proot}/cache')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Samples for Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allsides\n",
      "[  9 125 152 201]\n"
     ]
    }
   ],
   "source": [
    "agg = ds['agg']\n",
    "print(agg[136]['name'])\n",
    "\n",
    "ppp_start = 137\n",
    "all_sides_idx = np.random.randint(0, ppp_start, (2,))\n",
    "ppp_idx = np.random.randint(ppp_start, ppp_start+len(ds['ppp']), (2,))\n",
    "\n",
    "#sample_ids = np.concatenate((all_sides_idx, ppp_idx))\n",
    "sample_ids = np.array([9, 125, 152, 201])\n",
    "print(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| id | d1 | d2 |\n",
      "| - | - |\n",
      "| 0 | Privacy Policy   Important Update In September 2012, we announced that Instagram had been acquired by Facebook. | Welcome to the Google Privacy Policy When you use Google services, you trust us with your information. |\n",
      "| 1 | We knew that by teaming up with Facebook, we could build a better Instagram for you. | This Privacy Policy is meant to help you understand what data we collect, why we collect it, and what we do with it. |\n",
      "| 2 | Since then, we've been collaborating with Facebook's team on ways to do just that. | This is important; we hope you will take time to read it carefully. |\n",
      "| 3 | As part of our new collaboration, we've learned that by being able to share insights and information with each other, we can build better experiences for our users. | And remember, you can find controls to manage your information and protect your privacy and security at My Account. |\n",
      "| 4 | We're updating our Privacy Policy to highlight this new collaboration, but we want to make sure you understand that you still have control over who sees your photos. | Privacy Policy Last modified: June 30, 2015 ( view archived versions)  There are many different ways you can use our services - to search for and share information, to communicate with other people or to create new content. |\n",
      "| 5 | You still get to choose who can see your Instagram photos, and you still get to choose whether you post your photos on Facebook. | When you share information with us, for example by creating a Google Account, we can make those services even better - to show you more relevant search results and ads, to help you connect with people or to make sharing with others quicker and easier. |\n",
      "| 6 | So while we're looking forward to working closely with Facebook to build better experiences, we aren't changing the core features of the app that you've come to know and love. | As you use our services, we want you to be clear how we're using information and the ways in which you can protect your privacy. |\n",
      "| 7 | Our new Privacy Policy is effective on January 19, 2013. | Our Privacy Policy explains: What information we collect and why we collect it. |\n",
      "| 8 | To learn about how we treat information collected prior to January 19, 2013, please click here. | How we use that information. |\n",
      "| 9 | Privacy Policy Effective date: January 19, 2013  Welcome to Instagram (\"Instagram,\" \"we,\" \"us\" or \"our\"). | The choices we offer, including how to access and update information. |\n",
      "| 10 | Instagram provides a fast, beautiful and fun way for you to share media through our content-sharing platform. | We've tried to keep it as simple as possible, but if you're not familiar with terms like cookies, IP addresses, pixel tags and browsers, then read about these key terms first. |\n",
      "| 11 | Just snap a photo, choose a filter to transform the look and feel, add comments (if you like) and share! | Your privacy matters to Google so whether you are new to Google or a long-time user, please do take the time to get to know our practices - and if you have any questions contact us. |\n",
      "| 12 | Our Privacy Policy explains how we and some of the companies we work with collect, use, share and protect information in relation to our mobile services, web site, and any software provided on or in connection with Instagram services (collectively, the \"Service\"), and your choices about the collection and use of your information. | Device information We collect device-specific information (such as your hardware model, operating system version, unique device identifiers, and mobile network information including phone number). |\n",
      "| 13 | By using our Service you understand and agree that we are providing a platform for you to post content, including photos, comments and other materials (\"User Content\"), to the Service and to share User Content publicly. | Google may associate your device identifiers or phone number with your Google Account. |\n",
      "| 14 | This means that other Users may search for, see, use, or share any of your User Content that you make publicly available through the Service, consistent with the terms and conditions of this Privacy Policy and our Terms of Use (which can be found at http://instagram.com/about/legal/terms/). | Local storage We may collect and store information (including personal information) locally on your device using mechanisms such as browser web storage (including HTML 5) and application data caches. |\n",
      "| 15 | Our Policy applies to all visitors, users, and others who access the Service (\"Users\"). | Cookies and similar technologies We and our partners use various technologies to collect and store information when you visit a Google service, and this may include using cookies or similar technologies to identify your browser or device. |\n",
      "| 16 | Click on the links below to jump to each section of this Policy: Information We Collect How We Use Your Information Sharing of Your Information How We Store Your Information Your Choices About Your Information Children's Privacy Other Websites and Services How to Contact Us About a Deceased User How to Contact Us Changes to Our Privacy Policy   1. | We also use these technologies to collect and store information when you interact with services we offer to our partners, such as advertising services or Google features that may appear on other sites. |\n",
      "| 17 | INFORMATION WE COLLECT We collect the following types of information. | Our Google Analytics product helps businesses and site owners analyze the traffic to their websites and apps. |\n",
      "| 18 |  | When used in conjunction with our advertising services, such as those using the DoubleClick cookie, Google Analytics information is linked, by the Google Analytics customer or by Google, using Google technology, with information about visits to multiple sites. |\n",
      "\n",
      "| refs             |\n",
      "| ----             |\n",
      "| Companies collect information about users. The sole purpose of collecting information is to continually improve their services. |\n",
      "| Both companies provide general text on information they collect. This information is used to provide better services. |\n",
      "| Collects and shares information in order to provide better services to user.  |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples= agg.select(sample_ids)\n",
    "sid = 3\n",
    "sample = samples[sid]\n",
    "\n",
    "# sent tokenize each doc\n",
    "sents1 = sent_tokenize(sample['d1'])\n",
    "sents2 = sent_tokenize(sample['d2'])\n",
    "\n",
    "# even out list lengths\n",
    "len_max= max(len(sents1), len(sents2))\n",
    "sents1 += ['']*(len_max - len(sents1))\n",
    "sents2 += ['']*(len_max - len(sents2))\n",
    "\n",
    "\n",
    "# create md table for docs\n",
    "doc_table = '| id | d1 | d2 |\\n| - | - |\\n'\n",
    "for i, (s1, s2) in enumerate(zip(sents1, sents2)):\n",
    "    s1 = s1.strip().replace('\\n', ' ')\n",
    "    s2 = s2.strip().replace('\\n', ' ')\n",
    "    doc_table += f'| {i} | {s1} | {s2} |\\n'\n",
    "print(doc_table)\n",
    "\n",
    "# create md table for refs\n",
    "ref_table = (\n",
    "    f'| refs             |\\n'\n",
    "    f'| ----             |\\n'\n",
    "    f'| {sample[\"ref0\"]} |\\n'\n",
    "    f'| {sample[\"ref1\"]} |\\n'\n",
    "    f'| {sample[\"ref2\"]} |\\n'\n",
    ")\n",
    "if sample['ref3'] is not None:\n",
    "    ref_table += f'| {sample[\"ref3\"]} |\\n'\n",
    "print(ref_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Key\": \"news9\",\n",
      "    \"Left\": \"The Russian government successfully obtained access to U.S. voter registration databases in multiple states prior to the 2016 election, the federal official responsible for monitoring hacking said. Jeannette Manfra, the head of cybersecurity at the Department of Homeland Security, told NBC News Thursday that Russia targeted 21 states and managed to actually penetrate \\\"an exceptionally small number of them\\\" in an interview published Thursday. \\\"We were able to determine that the scanning and probing of voter registration databases was coming from the Russian government,\\\" Manfra added. Five states, including Texas and California, denied that they ever suffered attacks. Jeh Johnson, who was DHS secretary at the time, told NBC that states and the federal government should \\\"do something about it,\\\" though he lamented many of the targeted states haven't taken action since the election. Manfra disagreed, claiming that \\\"they have all taken it seriously.\\\" Several of these states, meanwhile, told NBC that the help they sought from the federal government didn't come soon enough. Some state officials said they didn't possess the right clearance level to properly communicate the details of the threats they faced -- an issue Manfra said is now being handled. Other states said they hadn't received any assistance from DHS. Russian targeting of voter registration databases became known in the months leading up to the election, when the FBI warned state governments that hackers had infiltrated the Illinois State Board of Elections and attempted to do the same in Arizona.\",\n",
      "    \"Right\": \"The head of cybersecurity at the Department of Homeland Security revealed Wednesday that Russia managed to hack into voter registration rolls of several states during the 2016 presidential election. U.S. intelligence official Jeanette Manfra told NBC News her department saw a small number of states where Moscow was \\\"successfully\\\" able to hack voters systems, despite there being no evidence that registration rolls were altered in anyway. \\\"We saw a targeting of 21 states and an exceptionally small number of them were actually successfully penetrated,\\\" she said. She declined to go into further detail about the classified information but said there was \\\"no doubt\\\" the Russian government was behind the attacks. Her comments came the same week Secretary of State Rex Tillerson confirmed that hackers were already targeting the upcoming midterm elections. \\\"I think it's important we just continue to say to Russia, 'Look, you think we don't see what you're doing. We do see it and you need to stop. If you don't, you're going to just continue to invite consequences for yourself,'\\\" Tillerson told Fox News. Following the 2016 presidential election, U.S. intelligence officials noted Russia's deliberate attempts to undermine American democracy by influencing voters across social media platforms. A special counsel was appointed shortly after to look into possible collusion between the Trump camp and Moscow. President Donald Trump has vehemently denied the White House colluded with Russia in any way.\",\n",
      "    \"Ahmed_Intersection\": \"The Russian government successfully obtained access to U.S. voter registration databases in multiple states prior to the 2016 election. Jeannette Manfra, the head of cybersecurity at the Department of Homeland Security, told NBC News that Russia targeted 21 states and managed to actually penetrate \\\"an exceptionally small number of them\\\".\",\n",
      "    \"Naman_Intersection\": \"Russia managed to hack into voter registration rolls of several states during the 2016 presidential election. The head of cybersecurity at the Department of Homeland Security, Jeanette Manfra told NBC News, \\\"We saw a targeting of 21 states and an exceptionally small number of them were actually successfully penetrated.\\\" \",\n",
      "    \"Helen_Intersection\": \"The Department of Homeland Security (DHS) said that Russia targeted 21 states and managed to actually penetrate \\\"an exceptionally small number of them\\\". to hack into voter registration rolls.\",\n",
      "    \"AllSides_Intersection\": \"The head of cybersecurity at the Department of Homeland Security revealed Wednesday that Russia managed to hack into voter registration rolls of several states during the 2016 presidential election.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(raw_ds['allsides'][9], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 24 (1298193447.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    sim_scores = util.cos_sim(emb1, emb2).cpu().numpy()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 24\n"
     ]
    }
   ],
   "source": [
    "def l2_dist(a, b):\n",
    "    if type(a) == np.ndarray:\n",
    "        a_sqr = np.sum(a**2, keepdims=True, axis=-1)\n",
    "        b_sqr = np.sum(b**2, keepdims=True, axis=-1).T\n",
    "        dists = np.sqrt(a_sqr + b_sqr - 2*a@b.T) \n",
    "        return dists\n",
    "    elif type(a) == torch.Tensor:\n",
    "        pass\n",
    "\n",
    "trgt = 1\n",
    "sample = samples[trgt]\n",
    "\n",
    "st = 0.73\n",
    "dt = 13.5\n",
    "\n",
    "print(sample['d1'])\n",
    "print(sample['d2'])\n",
    "s1 = sent_tokenize(sample['d1'])\n",
    "s2 = sent_tokenize(sample['d2'])\n",
    "\n",
    "emb1 = model.encode(s1)\n",
    "emb2 = model.encode(s2)\n",
    "\n",
    "sim_scores = util.cos_sim(emb1, emb2).cpu().numpy()\n",
    "dists = l2_dist(emb1, emb2)\n",
    "\n",
    "\n",
    "sim_preds = (sim_scores > st).astype(int)\n",
    "dist_preds = (dists < dt).astype(int)\n",
    "\n",
    "print(f'\\npairs within cosine similarity threshold t={st}')\n",
    "print(sim_preds.shape)\n",
    "print(sim_preds)\n",
    "\n",
    "print(f'\\npairs within distance threshold t={dt}')\n",
    "print(dist_preds.shape)\n",
    "print(dist_preds)\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=400)\n",
    "print(f'\\nsim scores (avg={np.mean(sim_scores)}:\\n{sim_scores}')\n",
    "print(f'\\ndists (avg={np.mean(dists)}):\\n{dists}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
