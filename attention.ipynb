{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71087aa5-60f7-432c-b340-0cd8a3ca7f48",
   "metadata": {},
   "source": [
    "# This notebook is meant to showcase computing attention with a causal mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f5b63-b900-4dc6-ba44-1ee211e86fbf",
   "metadata": {},
   "source": [
    "# Call Imports and Seed the Random Number Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b1ae58-effa-4fa5-9036-f5423d6eafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Set this to whatever you want\n",
    "seed = 10\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09124bfa-6599-4984-af87-ec1bd63cb113",
   "metadata": {},
   "source": [
    "# Make Random Q, K, and V tensors\n",
    "\n",
    "usually the inputs to the attention function get projected but for simplicity we'll just assume it happened already\n",
    "\n",
    "`T` for timestep  \n",
    "`d` for dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9324a94d-484c-4384-8f5d-f1ef2e94a212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q shape: torch.Size([3, 4])\n",
      "k shape: torch.Size([3, 4])\n",
      "v shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "T, d = 3, 4\n",
    "q, k, v = torch.rand((T, d*3)).chunk(3, dim=-1)\n",
    "\n",
    "print(f'q shape: {q.shape}')\n",
    "print(f'k shape: {k.shape}')\n",
    "print(f'v shape: {v.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b389eba-8f22-4a8b-baae-eb15bd7730c6",
   "metadata": {},
   "source": [
    "# Time to Compute Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6614a1-4ad4-42ba-b3c2-adb0653c1ea1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d}}\\right)V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53036284-3dfc-4420-a307-5614d064aa6c",
   "metadata": {},
   "source": [
    "# First Compute $\\frac{QK^{\\top}}{\\sqrt{d}}$\n",
    "\n",
    "This operation outputs a (T, T) matrix  \n",
    "The $n$th row refers to the $n$th token in the sequence  \n",
    "The $n$th column refers to the \"attention score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4548c258-90a8-4e24-8ad0-8fe61ab07d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0366, 0.4480, 0.8684],\n",
      "        [0.6112, 0.2692, 0.4616],\n",
      "        [0.3284, 0.1526, 0.4017]])\n"
     ]
    }
   ],
   "source": [
    "qk = (q@k.T)/np.sqrt(d)\n",
    "\n",
    "print(qk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbe83e-216e-4e72-a920-28f9de53826b",
   "metadata": {},
   "source": [
    "# Masking is applied by setting masked values to $-\\infty$ before softmax\n",
    "$\\oslash$ means element-wise division\n",
    "$$\n",
    "\\text{softmax}(x) = \\exp(x) \\oslash \\sum\\limits_{i}\\exp(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e7a375-3101-4314-bd93-1cf85243545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: tensor([0.1602, 0.6989, 0.0781, 0.5008, 0.2713])\n",
      "\n",
      "v with masked end value: tensor([0.1602, 0.6989, 0.0781, 0.5008,   -inf])\n",
      "\n",
      "apply softmax: tensor([0.1984, 0.3400, 0.1827, 0.2789, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# random example vector\n",
    "example = torch.rand(5)\n",
    "print(f'v: {example}')\n",
    "\n",
    "# Set last value to -inf\n",
    "example[-1] = float('-inf')\n",
    "print(f'\\nv with masked end value: {example}')\n",
    "\n",
    "# apply softmax after setting last value to -inf\n",
    "s_example = torch.softmax(example, dim=0)\n",
    "print(f'\\napply softmax: {s_example}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fae445-a170-4c0e-ab6d-20368736ce2b",
   "metadata": {},
   "source": [
    "# Now Apply Causal Attention Mask and Compute Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d996e8-4ac4-49cd-b12b-1344f1143fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask (True values are the ones that get masked out):\n",
      "tensor([[False,  True,  True],\n",
      "        [False, False,  True],\n",
      "        [False, False, False]])\n",
      "\n",
      "QK^T/(sqrt(d)) after applying softmax:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5847, 0.4153, 0.0000],\n",
      "        [0.3431, 0.2878, 0.3692]])\n"
     ]
    }
   ],
   "source": [
    "# Create attention mask\n",
    "attn_mask = torch.triu(\n",
    "    torch.ones((T, T), dtype=torch.bool),\n",
    "    diagonal=1\n",
    ")\n",
    "print('Attention mask (True values are the ones that get masked out):')\n",
    "print(attn_mask)\n",
    "\n",
    "# Apply attention mask\n",
    "sqk = qk.clone()\n",
    "sqk[attn_mask] = float('-inf')\n",
    "sqk = torch.softmax(sqk, dim=-1)\n",
    "print('\\nQK^T/(sqrt(d)) after applying softmax:')\n",
    "print(sqk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c6f6e-4674-430b-acbe-d67bc71cb672",
   "metadata": {},
   "source": [
    "# Now Matrix Multiply with V and you have your attention output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34380181-94f5-49a7-93a1-e96d266ecd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[0.2759, 0.8454, 0.4397, 0.1585],\n",
      "        [0.4682, 0.7469, 0.2908, 0.4935],\n",
      "        [0.6005, 0.5586, 0.2971, 0.6820]])\n"
     ]
    }
   ],
   "source": [
    "attn_out = sqk@v\n",
    "\n",
    "print('output:')\n",
    "print(attn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27304eb7-df9a-43d4-a9ed-6ad90cfd2240",
   "metadata": {},
   "source": [
    "# Compare with Original V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74209f38-4df9-4f2a-a6b1-575a02633256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:\n",
      "tensor([[0.2759, 0.8454, 0.4397, 0.1585],\n",
      "        [0.7389, 0.6082, 0.0813, 0.9651],\n",
      "        [0.7942, 0.2534, 0.3329, 0.9478]])\n",
      "\n",
      "QK^T/(sqrt(d)) after applying softmax:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5847, 0.4153, 0.0000],\n",
      "        [0.3431, 0.2878, 0.3692]])\n",
      "\n",
      "Attention Output:\n",
      "tensor([[0.2759, 0.8454, 0.4397, 0.1585],\n",
      "        [0.4682, 0.7469, 0.2908, 0.4935],\n",
      "        [0.6005, 0.5586, 0.2971, 0.6820]])\n"
     ]
    }
   ],
   "source": [
    "print('V:')\n",
    "print(v)\n",
    "\n",
    "print('\\nQK^T/(sqrt(d)) after applying softmax:')\n",
    "print(sqk)\n",
    "\n",
    "print('\\nAttention Output:')\n",
    "print(attn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35658a-2c4b-4065-9a78-afea895ef745",
   "metadata": {},
   "source": [
    "# Notice that row 0 of attention output is just the first value vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd5398f-fe2a-42c5-b610-fe977182d565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_out[0] == v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c57c8c-5c12-42c7-b99d-5424cc10d3c2",
   "metadata": {},
   "source": [
    "# Now see that row 1 of attention output is just a linear combination of the first 2 rows of V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399d39bc-2ec6-4210-a074-c3dee60ab51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare extracted output with manual computation\n",
    "(sqk@v)[1] == sqk[1, 0]*v[0] + sqk[1, 1]*v[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2f886-ed8d-4012-aafb-89bb7ebf0966",
   "metadata": {},
   "source": [
    "# Now see that row 2 of attention output is just a linear combination of all 3 rows of V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15e9267-ee6b-4df4-8961-b773f7a886be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sqk@v)[2] == sqk[2, 0]*v[0] + sqk[2, 1]*v[1] + sqk[2, 2]*v[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37ab7d-3f55-46fb-8ddf-5ba871e01a95",
   "metadata": {},
   "source": [
    "# Test Pytorch Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cadcbb5-c87a-4b9e-bdf4-e45b0bf58dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:\n",
      "tensor([[[ 1.3097,  0.2201, -0.2880, -0.8347, -1.2838,  1.1809,  0.0583,\n",
      "           2.3550, -0.0433,  0.6667],\n",
      "         [ 0.1308, -0.8500, -0.1962, -0.5518, -0.6516,  0.4247, -1.4717,\n",
      "          -0.1648, -1.2407,  0.2646],\n",
      "         [ 1.4802, -1.3781,  0.4998,  0.2795, -1.2944, -0.3256, -1.6201,\n",
      "           0.8233,  0.2742,  0.3658]],\n",
      "\n",
      "        [[ 1.1157,  0.9831, -1.6072,  1.6858, -0.5771, -0.1047,  0.2066,\n",
      "           1.0235, -0.4788, -2.2119],\n",
      "         [ 0.0888,  0.4549, -1.1206,  0.9442,  0.1810, -0.6077,  0.1736,\n",
      "           0.5794,  0.2213,  0.4951],\n",
      "         [ 1.5629,  0.1023,  1.7757, -0.5724, -0.2848, -1.9658, -1.2562,\n",
      "           0.4375,  0.5342,  2.2882]]])\n",
      "\n",
      "output:\n",
      "tensor([[[ 1.2394,  0.4094, -0.7183,  1.0527,  0.4229, -0.7041, -0.6246,\n",
      "           0.5600,  0.3418, -0.0489],\n",
      "         [ 1.2394,  0.4094, -0.7183,  1.0527,  0.4229, -0.7041, -0.6246,\n",
      "           0.5600,  0.3418, -0.0489],\n",
      "         [ 1.2394,  0.4094, -0.7183,  1.0527,  0.4229, -0.7041, -0.6246,\n",
      "           0.5600,  0.3418, -0.0489]],\n",
      "\n",
      "        [[ 0.6935, -0.6045,  0.0734, -0.1621,  0.7121, -0.0409, -0.4530,\n",
      "           0.8577,  0.2189,  0.5059],\n",
      "         [ 0.7460, -0.6403,  0.0638, -0.1397,  0.7584, -0.0596, -0.4831,\n",
      "           0.9090,  0.2403,  0.5342],\n",
      "         [ 0.7188, -0.6217,  0.0688, -0.1514,  0.7344, -0.0499, -0.4674,\n",
      "           0.8824,  0.2292,  0.5195]]], grad_fn=<TransposeBackward0>)\n",
      "\n",
      "attention_weights\n",
      "tensor([[[1.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5274, 0.4726, 0.0000],\n",
      "         [0.5779, 0.4221, 0.0000],\n",
      "         [0.5516, 0.4484, 0.0000]]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "d = 10\n",
    "mod = nn.MultiheadAttention(d, num_heads=1, batch_first=True)\n",
    "q, k, v = torch.randn(2, 3, 10*3).chunk(3, dim=-1)\n",
    "\n",
    "pad_mask = torch.triu(torch.ones(v.shape[:2], dtype=torch.bool), diagonal=1)\n",
    "out, out_weights = mod(q, k, v, key_padding_mask=pad_mask)\n",
    "\n",
    "print('V:')\n",
    "print(v, end='\\n\\n')\n",
    "\n",
    "print('output:')\n",
    "print(out, end='\\n\\n')\n",
    "\n",
    "print('attention_weights')\n",
    "print(out_weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
