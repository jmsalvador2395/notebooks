{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ca8eb0-ab15-4bbb-a92b-d7581e858ce7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a08c4bb6-418a-4c9a-82e2-69cdf7efe935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610e22e-6a63-470d-abde-5df43288542b",
   "metadata": {},
   "source": [
    "# Load CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858bd65c-f24d-47c1-9e86-9f73d6780b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.98k/9.98k [00:00<00:00, 23.0MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 119M/119M [00:09<00:00, 11.9MB/s]\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23.8M/23.8M [00:01<00:00, 15.6MB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 130774.98 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 238046.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['img', 'fine_label', 'coarse_label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['img', 'fine_label', 'coarse_label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset('cifar100',\n",
    "                           cache_dir='./cache',\n",
    "                           trust_remote_code=True)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06b44d-dd99-48b7-a151-45e0d4897361",
   "metadata": {},
   "source": [
    "# Get Image Size and Set Patch Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b70c6ce-3d1c-4129-8602-2ce2e17519a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 32, 32])\n",
      "Patch shape: [3, 4, 4]\n",
      "# Patches: 64\n"
     ]
    }
   ],
   "source": [
    "img = pil_to_tensor(ds['train'][0]['img'])\n",
    "\n",
    "C, W, H = img.shape\n",
    "Cp, Wp, Hp = C, 4, 4\n",
    "\n",
    "img_shape = list(img.shape)\n",
    "patch_shape = [Cp, Wp, Hp]\n",
    "num_patches = int(np.prod(img_shape)/np.prod(patch_shape))\n",
    "\n",
    "print(f'Image shape: {img.shape}')\n",
    "print(f'Patch shape: {patch_shape}')\n",
    "print(f'# Patches: {num_pataches}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d5188-0870-4159-93c6-2a950ea411a7",
   "metadata": {},
   "source": [
    "# Test How to Patchify Efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c5fce9-0ce0-4dbf-804b-7948f99dfca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48])\n",
      "torch.Size([3, 8, 8, 4, 4])\n",
      "torch.Size([48])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "true_patch = img[:Cp, :Wp, :Hp].flatten()\n",
    "print(true_patch.shape)\n",
    "#test_patch = torch.ones(true_patch.shape)\n",
    "test_patch = img.unfold(1, Wp, Wp).unfold(2, Hp, Hp)\n",
    "print(test_patch.shape)\n",
    "test_patch = test_patch.permute(1, 2, 0, 3, 4).reshape((num_patches, -1))[0]\n",
    "print(test_patch.shape)\n",
    "\n",
    "print(true_patch == test_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19f072f5-5fdd-481f-9959-e7b55c712fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 5, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 3, 4, 6)\n",
    "print(a.shape)\n",
    "a.unfold(1, 1, 1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
